---
layout: post
title: "[TIL] 2025-06-09 / MLP 신경망 모델"
date: 2025-06-09 19:00:00 +0900
categories: 
  - til
  - main-camp
---

* toc
{:toc}

## 📖 Today I Learned
### MLP 신경망 모델

---

#### - **MLP(Multi-Layer Perceptron)**
- 가장 기본적인 형태의 인공신경망 구조  
- 입력층(Input layer), 은닉층(Hidden layer), 출력층(Output layer)으로 구성됨  
- 각 층은 여러 개의 노드(Neuron)를 가지며, **전층 연결(Fully Connected)** 구조로 되어 있음  
- 딥러닝 모델의 기본이 되는 구조로 분류, 회귀 문제 등 전반적인 태스크에 사용됨

#### - 신경망 구성 요소

| 구성 요소       | 설명                                      |
|----------------|-------------------------------------------|
| 입력층          | 모델이 입력받는 데이터. 특성(Feature) 수와 같음 |
| 은닉층          | 입력 정보를 비선형적으로 조합하여 특징 추출       |
| 출력층          | 최종 결과 출력. 문제 유형에 따라 노드 수 달라짐     |
| 가중치          | 각 노드 간 연결 강도. 학습 과정에서 최적화됨        |
| 활성화 함수     | 입력값을 비선형적으로 변환하여 다음 층으로 전달     |
| 손실 함수       | 예측값과 실제값의 차이를 수치화한 값               |
| 옵티마이저      | 손실을 최소화하기 위해 가중치를 업데이트하는 방식    |

#### - 학습 과정
1. **순전파 (Forward Propagation)**  
    - 입력 데이터를 기반으로 예측값 생성
2. **오차 계산 (Loss Function)**  
    - 예측값과 실제값 사이의 오차 계산
3. **역전파 (Backpropagation)**  
    - 오차를 기반으로 가중치의 그래디언트(기울기) 계산
4. **가중치 업데이트 (Optimizer)**  
    - 옵티마이저를 사용해 가중치 조정
이 과정을 여러 번 반복하면서 모델 성능을 향상시킴

#### - 활성화 함수 종류

| 함수         | 특징                                           |
|--------------|------------------------------------------------|
| Sigmoid      | 0~1 범위 출력, 이진 분류에 사용됨                |
| Tanh         | -1~1 출력, Sigmoid보다 중심성이 있음            |
| ReLU         | 0 이상이면 그대로, 음수면 0. 속도 빠르고 성능 좋음 |
| Softmax      | 다중 클래스 분류의 출력층에서 사용됨              |

#### - 장점
- 구현이 간단하고 범용적인 모델  
- 비선형 문제도 해결 가능  
- 다양한 입력 형태(숫자, 벡터 등)에 적용 가능

#### - 단점
- 이미지, 시계열 등 구조적인 데이터에는 적합하지 않음  
- 과적합 위험 있음 → Dropout, 정규화 필요  
- 층이 많아질수록 학습 속도 느려지고, 그래디언트 소실 가능성 있음

#### - PyTorch 예제 코드

```python
import torch
import torch.nn as nn

class MLP(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(MLP, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, output_dim)
        )
    
    def forward(self, x):
        return self.net(x)

model = MLP(input_dim=10, hidden_dim=64, output_dim=1)
```

#### - 사용 예시
- 숫자 분류 (MNIST 등)  
- 신용 등급 예측  
- 단순 회귀 분석  
- 기본 벡터 임베딩 기반 분류 문제

<!-- --- -->

<!-- <h2> 💬 </h2> -->

<!-- <h4>  </h4> -->